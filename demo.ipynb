{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/lei/.cache/torch_extensions/py38_cu102 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/lei/.cache/torch_extensions/py38_cu102/torchac_backend/build.ninja...\n",
      "Building extension module torchac_backend...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module torchac_backend...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from entropy_model import EntropyBottleneck\n",
    "import tqdm\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 2, 2, 2 ]),\n",
    "                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "def plot_image(x_tensor):\n",
    "    plt.imshow(invTrans(x_tensor).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "dset = datasets.SVHN(root='data/', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n"
     ]
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(dset, batch_size=128, num_workers=2, pin_memory=True, shuffle=True)\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "class AutoencoderCompressor(torch.nn.Module):\n",
    "    def __init__(self, bottleneck_dim=32, img_size=(32, 32, 3), dim=16):\n",
    "        super(AutoencoderCompressor, self).__init__()\n",
    "        self.encoder = Encoder(img_size, dim)\n",
    "        self.decoder = Decoder(img_size, dim)\n",
    "        self.entropy_bottleneck = EntropyBottleneck(bottleneck_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_tilde, likelihood = self.entropy_bottleneck(z) # use uniform noise during training, hard quantization during eval\n",
    "        x_hat = self.decoder(z_tilde)\n",
    "        return x_hat, likelihood\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, img_size, dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.img_size = img_size\n",
    "\n",
    "\n",
    "        self.features_to_image = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(4 * dim),\n",
    "            torch.nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(2 * dim),\n",
    "            torch.nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(dim),\n",
    "            torch.nn.ConvTranspose2d(dim, self.img_size[2], 4, 2, 1),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.features_to_image(input_data)\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, img_size, dim):\n",
    "        \"\"\"\n",
    "        img_size : (int, int, int)\n",
    "            Height and width must be powers of 2.  E.g. (32, 32, 1) or\n",
    "            (64, 128, 3). Last number indicates number of channels, e.g. 1 for\n",
    "            grayscale or 3 for RGB\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.image_to_features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.img_size[2], dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.image_to_features(input_data)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoencoderCompressor(bottleneck_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat, lik = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 32, 32]), torch.Size([128, 128, 2, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat.shape, lik.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def rate_loss(likelihoods):\n",
    "    batch_size = likelihoods.shape[0]\n",
    "    rate_batch = -torch.sum(torch.log2(likelihoods)) # total rate of batch (factorized prior)\n",
    "    rate_per_sample = rate_batch / batch_size # rate per sample\n",
    "    return rate_per_sample\n",
    "\n",
    "def distortion_loss(x, x_hat):\n",
    "    # SED = squared-error-distortion\n",
    "    SED_batch = torch.linalg.vector_norm(x-x_hat, dim=(1,2,3))**2 # vector of SED for each element in batch\n",
    "    SED_per_sample = torch.mean(SED_batch)\n",
    "    return SED_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train_one_epoch(model, optimizer, loader, lmbda):\n",
    "    model.train()\n",
    "    \n",
    "    rate_epoch, distortion_epoch = 0, 0\n",
    "    for x, _ in loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        x_hat, likelihoods = model(x)  # Forward pass.\n",
    "        rate = rate_loss(likelihoods) # compute average rate\n",
    "        # rate = -torch.sum(torch.log2(likelihoods))\n",
    "        distortion = distortion_loss(x, x_hat) # compute average distortion\n",
    "        RD_loss = rate + lmbda * distortion\n",
    "        RD_loss.backward()  # Backward pass.\n",
    "        optimizer.step()  # Update model parameters.\n",
    "\n",
    "        rate_epoch += rate.item()\n",
    "        distortion_epoch += distortion.item()\n",
    "\n",
    "    return rate_epoch / len(loader), distortion_epoch / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    for data in loader:\n",
    "        data.cuda()\n",
    "        logits = model(data.pos, data.batch)\n",
    "        pred = logits.argmax(dim=-1)\n",
    "        total_correct += int((pred == data.y).sum())\n",
    "\n",
    "    return total_correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoencoderCompressor(bottleneck_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, rate: 1331.3043 bps, distortion: 123.7885\n",
      "Epoch: 02, rate: 309.5639 bps, distortion: 82.5721\n",
      "Epoch: 03, rate: 156.9949 bps, distortion: 81.0199\n",
      "Epoch: 04, rate: 111.4237 bps, distortion: 79.1909\n",
      "Epoch: 05, rate: 89.9577 bps, distortion: 77.8102\n",
      "Epoch: 06, rate: 77.4923 bps, distortion: 76.1634\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    r, d = train_one_epoch(model, optimizer, loader, lmbda=1.)\n",
    "    # test_acc = test(model, test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, rate: {r:.4f} bps, distortion: {d:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pccai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "183e7f806bcbb61d663dad6aba9fc871a48483ac915196e6d61b7057aa352d22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
