{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from entropy_model import EntropyBottleneck\n",
    "import tqdm\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 2, 2, 2 ]),\n",
    "                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "def plot_image(x_tensor):\n",
    "    plt.imshow(invTrans(x_tensor).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "dset = datasets.SVHN(root='data/', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(dset, batch_size=256)\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "class AutoencoderCompressor(torch.nn.Module):\n",
    "    def __init__(self, bottleneck_dim=32, img_size=(32, 32, 3), dim=16):\n",
    "        super(AutoencoderCompressor, self).__init__()\n",
    "        self.encoder = Encoder(img_size, dim)\n",
    "        self.decoder = Decoder(img_size, dim)\n",
    "        self.entropy_bottleneck = EntropyBottleneck(bottleneck_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_tilde, likelihood = self.entropy_bottleneck(z) # use uniform noise during training, hard quantization during eval\n",
    "        x_hat = self.decoder(z_tilde)\n",
    "        return x_hat, likelihood\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, img_size, dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.img_size = img_size\n",
    "\n",
    "\n",
    "        self.features_to_image = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(4 * dim),\n",
    "            torch.nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(2 * dim),\n",
    "            torch.nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(dim),\n",
    "            torch.nn.ConvTranspose2d(dim, self.img_size[2], 4, 2, 1),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.features_to_image(input_data)\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, img_size, dim):\n",
    "        \"\"\"\n",
    "        img_size : (int, int, int)\n",
    "            Height and width must be powers of 2.  E.g. (32, 32, 1) or\n",
    "            (64, 128, 3). Last number indicates number of channels, e.g. 1 for\n",
    "            grayscale or 3 for RGB\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.image_to_features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.img_size[2], dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.image_to_features(input_data)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoencoderCompressor(bottleneck_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 32, 32])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat, lik = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 3, 32, 32]), torch.Size([256, 128, 2, 2]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat.shape, lik.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def rate_loss(likelihoods):\n",
    "    batch_size = likelihoods.shape[0]\n",
    "    rate_batch = -torch.sum(torch.log2(likelihoods)) # total rate of batch (factorized prior)\n",
    "    rate_per_sample = rate_batch / batch_size # rate per sample\n",
    "    return rate_per_sample\n",
    "\n",
    "def distortion_loss(x, x_hat):\n",
    "    # SED = squared-error-distortion\n",
    "    SED_batch = torch.linalg.vector_norm(x-x_hat, dim=(1,2,3))**2 # vector of SED for each element in batch\n",
    "    SED_per_sample = torch.mean(SED_batch)\n",
    "    return SED_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train_one_epoch(model, optimizer, loader, lmbda):\n",
    "    model.train()\n",
    "    \n",
    "    rate_epoch, distortion_epoch = 0, 0\n",
    "    for x, _ in tqdm.tqdm(loader):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        x_hat, likelihoods = model(x)  # Forward pass.\n",
    "        rate = rate_loss(likelihoods) # compute average rate\n",
    "        # rate = -torch.sum(torch.log2(likelihoods))\n",
    "        distortion = distortion_loss(x, x_hat) # compute average distortion\n",
    "        RD_loss = rate + lmbda * distortion\n",
    "        RD_loss.backward()  # Backward pass.\n",
    "        optimizer.step()  # Update model parameters.\n",
    "\n",
    "        rate_epoch += rate.item()\n",
    "        distortion_epoch += distortion.item()\n",
    "\n",
    "    return rate_epoch / len(loader), distortion_epoch / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    for data in loader:\n",
    "        data.cuda()\n",
    "        logits = model(data.pos, data.batch)\n",
    "        pred = logits.argmax(dim=-1)\n",
    "        total_correct += int((pred == data.y).sum())\n",
    "\n",
    "    return total_correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoencoderCompressor(bottleneck_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:24<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, rate: 1857.8628, distortion: 168.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:23<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, rate: 802.9458, distortion: 84.3070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:23<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, rate: 377.0806, distortion: 81.1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/287 [00:00<00:21, 12.53it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    r, d = train_one_epoch(model, optimizer, loader, lmbda=1.)\n",
    "    # test_acc = test(model, test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, rate: {r:.4f} bps, distortion: {d:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pccai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "183e7f806bcbb61d663dad6aba9fc871a48483ac915196e6d61b7057aa352d22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
